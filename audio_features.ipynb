{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre recognition: feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audio genre recognition pipeline:\n",
    "1. GTZAN\n",
    "2. pre-processing\n",
    "3. unsupervised feature extraction\n",
    "4. classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open questions:\n",
    "* Rescale the dataset ? We need to for the algorithm to converge.\n",
    "    * Rescale $n$ features in [0,1] --> converge. But we need to learn the transform.\n",
    "    * Normalize each sample to unit norm --> converge. But higher objective and less sparse Z. We also loose the generative ability of our model.\n",
    "* Is there a way to programmatically assess convergence ? Easy for us to look at the objective function, but for a machine.\n",
    "* Store data in float64 ? Or compute in float32 ?\n",
    "\n",
    "Observations:\n",
    "* Memory efficiency:\n",
    "    * m=64, 20 songs: 600 MiB --> 170 MiB (pyul mem optimization)\n",
    "    * m=64, 40 songs: 900 MiB --> 170 MiB (pyul mem optimization)\n",
    "    * m=128, 200 songs: 800 MiB (pyul mem optimization)\n",
    "    * m=128, 400 songs: 2 GiB (pyul mem optimization)\n",
    "* Time efficiency:\n",
    "    * m=64, 20 songs: 370s\n",
    "    * m=128, 400 songs: 19636s (pyul mem optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import auto-encoder definition.\n",
    "%run -n auto_encoder.ipynb\n",
    "#import auto_encoder\n",
    "\n",
    "# Profiling.\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "import objgraph\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join('data', 'audio_v2_full.hdf5')\n",
    "audio = h5py.File(filename, 'r')\n",
    "\n",
    "# Display HDF5 attributes.\n",
    "print('Attributes:')\n",
    "for attr in audio.attrs:\n",
    "    print('  {} = {}'.format(attr, audio.attrs[attr]))\n",
    "\n",
    "# Show datasets, their dimensionality and data type.\n",
    "print('Datasets:')\n",
    "for dname, dset in audio.items():\n",
    "    print('  {:2}: {:24}, {}'.format(dname, dset.shape, dset.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datinfo(X, name='Dataset'):\n",
    "    r\"\"\"Print dataset size and dimensionality\"\"\"\n",
    "    print('{}:\\n'\n",
    "          '  size: N={:,} x n={} -> {:,} floats\\n'\n",
    "          '  dim: {:,} features per clip\\n'\n",
    "          '  shape: {}'\n",
    "          .format(name, np.prod(X.shape[:-1]), X.shape[-1],\n",
    "                  np.prod(X.shape), np.prod(X.shape[2:]), X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose dataset.\n",
    "X = audio.get('Xs')\n",
    "\n",
    "# Full dataset.\n",
    "Ngenres, Nclips, Nframes, _, n = X.shape\n",
    "datinfo(X, 'Full dataset')\n",
    "print(type(X))\n",
    "\n",
    "# Reduce data size.\n",
    "Ngenres, Nclips = 4, 100\n",
    "\n",
    "# Load data into memory as a standard NumPy array.\n",
    "X = X[:Ngenres,:Nclips,...]\n",
    "datinfo(X, 'Reduced dataset')\n",
    "print(type(X))\n",
    "\n",
    "# Resize in place without memory loading via hyperslab.\n",
    "# Require chunked datasets.\n",
    "#X.resize((Ngenres, Nclips, Nframes, 2, n))\n",
    "\n",
    "# Squeeze dataset to a 2D array. The auto-encoder does not\n",
    "# care about the underlying structure of the dataset.\n",
    "X.resize(Ngenres * Nclips * Nframes * 2, n)\n",
    "print('Data: {}, {}'.format(X.shape, X.dtype))\n",
    "\n",
    "# Independently rescale each feature.\n",
    "# To be put in an sklearn Pipeline to avoid transductive learning.\n",
    "X -= np.min(X, axis=0)\n",
    "X /= np.max(X, axis=0)\n",
    "\n",
    "# Independently normalize each sample.\n",
    "#X /= np.linalg.norm(X, axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters:\n",
    "* m:  number of atoms in the dictionary, sparse code length\n",
    "* ld: weigth of the dictionary l2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 128  # 512\n",
    "ld = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of training data and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = Ngenres * Nclips * Nframes * 2\n",
    "sizeX = N * n / 2.**20\n",
    "sizeZ = N * m / 2.**20\n",
    "sizeD = n * m / 2.**10\n",
    "sizeE = m * n / 2.**10\n",
    "# 64 bits float\n",
    "print('Size X: {:.1f} M --> {:.1f} MiB'.format(sizeX, sizeX*8))\n",
    "print('Size Z: {:.1f} M --> {:.1f} MiB'.format(sizeZ, sizeZ*8))\n",
    "print('Size D: {:.1f} k --> {:.1f} kiB'.format(sizeD, sizeD*8))\n",
    "print('Size E: {:.1f} k --> {:.1f} kiB'.format(sizeE, sizeE*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 200 10 | 200 15\n",
    "ae = auto_encoder(m=m, ld=ld, rtol=1e-5, xtol=None, N_inner=200, N_outer=10)\n",
    "tstart = time.time()\n",
    "Z = ae.fit_transform(X)\n",
    "print('Elapsed time: {:.0f} seconds'.format(time.time() - tstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    %prun Z = ae.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    objgraph.show_most_common_types()\n",
    "    from pyunlocbox import solvers, functions\n",
    "    %mprun -f ae.fit_transform -f ae._minD -f ae._minZ -f solvers.solve -f solvers.forward_backward._pre -f solvers.forward_backward._fista -f functions.norm_l1._prox -T profile.txt ae.fit_transform(X)\n",
    "    #%mprun -f solvers.solve -f solvers.forward_backward._pre -f solvers.forward_backward._fista -f functions.norm_l1._prox -T profile.txt ae.fit_transform(X)\n",
    "    gc.collect()\n",
    "    objgraph.show_most_common_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from pympler import tracker\n",
    "    tr = tracker.SummaryTracker()\n",
    "    Z = ae.fit_transform(X)\n",
    "    tr.print_diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae.plot_objective()\n",
    "objective(X, Z, ae.D, ae.ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sparse_codes(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* The learned atoms seem to represent harmonies and harmonics.\n",
    "* The atoms themselves look sparse. Should we add some prior knowledge on the dictionary ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary(ae.D)\n",
    "atoms(ae.D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store more Z when the various approximations will be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = os.path.join('data', 'features.hdf5')\n",
    "\n",
    "# Remove existing HDF5 file without warning if non-existent.\n",
    "try:\n",
    "    os.remove(filename)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# Create HDF5 file and datasets.\n",
    "features = h5py.File(filename, 'w')\n",
    "\n",
    "# Metadata.\n",
    "features.attrs['sr'] = audio.attrs['sr']\n",
    "features.attrs['labels'] = audio.attrs['labels']\n",
    "\n",
    "# Data.\n",
    "features.create_dataset('X', data=X.reshape(Ngenres, Nclips, Nframes, 2, n), dtype='float32')\n",
    "features.create_dataset('Z', data=Z.reshape(Ngenres, Nclips, Nframes, 2, Z.shape[-1]), dtype='float32')\n",
    "features.create_dataset('D', data=ae.D, dtype='float32')\n",
    "\n",
    "# Show datasets, their dimensionality and data type.\n",
    "print('Datasets:')\n",
    "for dname, dset in features.items():\n",
    "    print('  {:2}: {:22}, {}'.format(dname, dset.shape, dset.dtype))\n",
    "\n",
    "# Display HDF5 attributes.\n",
    "print('Attributes:')\n",
    "for name, value in features.attrs.items():\n",
    "    print('  {} = {}'.format(name, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
