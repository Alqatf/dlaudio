{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy auto-encoder: comparison with Xavier Primal-Dual matlab implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from pyunlocbox import functions, solvers\n",
    "import time\n",
    "import scipy, matplotlib, pyunlocbox  # For versions only.\n",
    "print('Software versions:')\n",
    "for pkg in [np, matplotlib, scipy, pyunlocbox]:\n",
    "    print('  %s: %s' % (pkg.__name__, pkg.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The $\\lambda$ are the relative importance of each term in the composite objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_d = 10  # Xavier sets the weight of the L1 regularization to 1e-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The set of data vectors $X \\in R^{n \\times N}$ is given by patches extracted from a grayscale image.\n",
    "* There is as many patches as pixels in the image.\n",
    "* The saved patches already have zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data/xavier_X.mat')\n",
    "X = mat['X']\n",
    "\n",
    "n, N = X.shape\n",
    "Np = np.sqrt(n)\n",
    "print('N = %d samples with dimensionality n = %d (patches of %dx%d).' % (N, n, Np, Np))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "patches = [24, 1000, 2004, 10782]\n",
    "for k in range(len(patches)):\n",
    "    patch = patches[k]\n",
    "    img = np.reshape(X[:, patch], (Np, Np))\n",
    "    plt.subplot(1, 4, k+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Patch %d' % patch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $Z$ is drawn from a uniform distribution in ]0,1[.\n",
    "* Same for $D$. Its columns were then normalized to unit L2 norm.\n",
    "* The sparse code dimensionality $m$ should be greater than $n$ for an overcomplete representation but much smaller than $N$ to avoid over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data/xavier_initZD.mat')\n",
    "Zinit = mat['Zinit']\n",
    "Dinit = mat['Dinit']\n",
    "\n",
    "m, N = Zinit.shape\n",
    "n, m = Dinit.shape\n",
    "print('Sparse code dimensionality m = %d --> %s dictionary' % (m, 'overcomplete' if m > n else 'undercomplete'))\n",
    "\n",
    "print('mean(Z) = %f' % np.mean(Zinit))\n",
    "\n",
    "d = np.sqrt(np.sum(Dinit*Dinit, axis=0))\n",
    "print('Constraints on D: %s' % np.alltrue(d <= 1+1e-15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $X \\in R^{n \\times N}$, solve $\\min\\limits_{Z \\in R^{m \\times N}, D \\in R^{n \\times m}} \\frac{\\lambda_d}{2} \\|X - DZ\\|_F^2 + \\|Z\\|_1$ s.t. $\\|d_i\\|_2 \\leq 1$, $i = 1, \\ldots, m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solver numeric parameters.\n",
    "N_outer = 15  # Xavier uses 15.\n",
    "N_inner = 100  # Xavier uses 1e-5 or 1e-7 and 100 iterations for inner loops.\n",
    "\n",
    "# Static loss function definitions.\n",
    "g_z = functions.norm_l1()\n",
    "g_d1 = functions.proj_b2(epsilon=1)  # L2-ball indicator function.\n",
    "g_d = functions.func()\n",
    "g_d._eval = lambda Dt: 0\n",
    "g_d._prox = lambda Dt,_: g_d1._prox(Dt.T, 0).T  # Constraints on lines of D^T.\n",
    "\n",
    "# Initialization.\n",
    "Z = Zinit\n",
    "D = Dinit\n",
    "objective_z = []\n",
    "objective_d = []\n",
    "objective_g = []\n",
    "tstart = time.time()\n",
    "\n",
    "# Multi-variate non-convex optimization (outer loop).\n",
    "for k in np.arange(N_outer):\n",
    "\n",
    "    # Convex minimization for Z.\n",
    "    f_z = functions.norm_l2(lambda_=l_d/2., A=D, y=X, tight=False)\n",
    "    L = l_d * la.norm(np.dot(D.T, D))  # Lipschitz continuous gradient.\n",
    "    solver = solvers.forward_backward(step=1./L, method='FISTA')\n",
    "    ret = solvers.solve([f_z, g_z], Z, solver, rtol=None, xtol=1e-6, maxit=N_inner, verbosity='NONE')\n",
    "    Z = ret['sol']\n",
    "    objective_z.extend(ret['objective'])\n",
    "    objective_d.extend(np.zeros(np.shape(ret['objective'])))\n",
    "    \n",
    "    # Convex minimization for D.\n",
    "    f_d = functions.norm_l2(lambda_=l_d/2., A=Z.T, y=X.T, tight=False)\n",
    "    L = l_d * la.norm(np.dot(Z, Z.T))  # Lipschitz continuous gradient.\n",
    "    solver = solvers.forward_backward(step=1./L, method='FISTA')\n",
    "    ret = solvers.solve([f_d, g_d], D.T, solver, rtol=None, xtol=1e-6, maxit=N_inner, verbosity='NONE')\n",
    "    D = ret['sol'].T\n",
    "    objective_d.extend(ret['objective'])\n",
    "    objective_z.extend(np.zeros(np.shape(ret['objective'])))\n",
    "    \n",
    "    # Global objective (the indicators are 0).\n",
    "    objective_g.append(g_z.eval(Z) + f_d.eval(D.T))\n",
    "\n",
    "print('Elapsed time: %d seconds' % (time.time() - tstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.semilogy(np.array(objective_z)[:, 0], label='Z: data term')\n",
    "plt.semilogy(np.array(objective_z)[:, 1], label='Z: prior term')\n",
    "#plt.semilogy(np.sum(objective[:,0:2], axis=1), label='Z: sum')\n",
    "plt.semilogy(np.array(objective_d)[:, 0], label='D: data term')\n",
    "niter = np.shape(objective_z)[0]\n",
    "plt.xlim(0, niter-1)\n",
    "plt.title('Sub-problems convergence')\n",
    "plt.xlabel('Iteration number (inner loops)')\n",
    "plt.ylabel('Objective function value')\n",
    "plt.grid(True); plt.legend(); plt.show()\n",
    "print('Inner loop: %d iterations' % niter)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(objective_g)\n",
    "niter = np.shape(objective_g)[0]\n",
    "plt.xlim(0, niter-1)\n",
    "plt.title('Global convergence')\n",
    "plt.xlabel('Iteration number (outer loop)')\n",
    "plt.ylabel('Objective function value')\n",
    "plt.grid(True); plt.show()\n",
    "print('Outer loop: %d iterations\\n' % niter)\n",
    "\n",
    "print('g_z(Z) = %e' % g_z.eval(Z))\n",
    "print('f_z(Z,D) = %e' % f_z.eval(Z))\n",
    "print('f_d(D,Z) = %e' % f_d.eval(D.T))\n",
    "print('g_z(Z) + f_d(D,Z) = %e' % objective_g[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution from Xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data/xavier_ZD.mat')\n",
    "Zxavier = mat['Z']\n",
    "Dxavier = mat['D']\n",
    "print('Elapsed time: %d seconds' % mat['exectime'])\n",
    "\n",
    "g_z = functions.norm_l1()\n",
    "f_z = functions.norm_l2(lambda_=l_d/2., A=Dxavier, y=X, tight=False)\n",
    "f_d = functions.norm_l2(lambda_=l_d/2., A=Zxavier.T, y=X.T, tight=False)\n",
    "\n",
    "print('g_z(Z) = %e' % g_z.eval(Zxavier))\n",
    "print('f_z(Z,D) = %e' % f_z.eval(Zxavier))\n",
    "print('f_d(D,Z) = %e' % f_d.eval(Dxavier.T))\n",
    "print('g_z(Z) + f_d(D,Z) = %e' % (g_z.eval(Zxavier) + f_d.eval(Dxavier.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sparse_code(Z):\n",
    "    nnz = np.count_nonzero(Z)\n",
    "    #nnz = np.sum(np.abs(Z) < 1e-4)\n",
    "    print('Sparsity of Z: %d non-zero entries out of %d entries, i.e. %.1f%%.' % (nnz, Z.size, 100.*nnz/Z.size))\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.spy(Z, precision=0, aspect='auto')\n",
    "    plt.xlabel('N = %d samples' % N)\n",
    "    plt.ylabel('m = %d atoms' % m)\n",
    "    plt.show()\n",
    "\n",
    "sparse_code(Zxavier)\n",
    "sparse_code(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dictionary(D):\n",
    "\n",
    "    d = np.sqrt(np.sum(D*D, axis=0))\n",
    "    print('Constraints on D: %s' % np.alltrue(d <= 1+1e-15))\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(d, 'b.')\n",
    "    plt.ylim(0.5, 1.5)\n",
    "    plt.xlim(0, m-1)\n",
    "    plt.title('Dictionary atom norms')\n",
    "    plt.xlabel('Atom [1,m]')\n",
    "    plt.ylabel('Norm [0,1]')\n",
    "    plt.grid(True); plt.show()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.spy(D, precision=1e-2, aspect='auto')\n",
    "    plt.xlabel('m = %d atoms' % (m,))\n",
    "    plt.ylabel('data dimensionality of n = %d' % n)\n",
    "    plt.show()\n",
    "\n",
    "    #plt.scatter to show intensity\n",
    "\n",
    "dictionary(Dxavier)\n",
    "dictionary(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def atoms(D):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    Nx = np.ceil(np.sqrt(m))\n",
    "    Ny = np.ceil(m / float(Nx))\n",
    "    for k in np.arange(m):\n",
    "        plt.subplot(Ny, Nx, k)\n",
    "        img = D[:,k].reshape(Np, Np)\n",
    "        plt.imshow(img, cmap='gray')  # vmin=0, vmax=1 to disable normalization.\n",
    "        plt.axis('off')\n",
    "\n",
    "atoms(Dxavier)\n",
    "atoms(D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
